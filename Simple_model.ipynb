{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ondraperny/BI-BAP-2020/blob/master/Simple_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU19OXW480YR",
        "colab_type": "text"
      },
      "source": [
        "# Simple model\n",
        "---\n",
        "### Code parts(description of colab cells):\n",
        "**Imports** - contain all used imports with descriptions \\\n",
        "**Colab essentials** - when running code on Colab, mount Google Drive so data can be read from there. \\\n",
        "**Constants declaration** - declaring input parameters \\\n",
        "**Data augmentation** - defining functions for importing and augmenting data in Keras \\\n",
        "**Auxiliary functions** - any functions non-related to ML training, usually for graphical output \\\n",
        "**Model definition** - Defining keras models \\\n",
        "**Training model** - initialization and training model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHZh_eZa6csV",
        "colab_type": "text"
      },
      "source": [
        "## Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbw0u9Xp2wwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For graphical outpus, images preview and training results plot representation\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "from tensorflow.keras import backend\n",
        "# Generator used for loading data into Keras model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Essentials for creating model architecture, model class, layers and optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import he_uniform \n",
        "# Logger for logging results from training model\n",
        "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# System functions and path processing\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Support functions for saving and loading model\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj77E8dk-gzD",
        "colab_type": "text"
      },
      "source": [
        "## Colab essentials\n",
        "Running code on Colab and local requires slightly different, prerequisites (as different paths, etc.)\n",
        "For differentiating where code is run, variable IN_COLAB is used, if True then run is in Colab (so rest of code can reflect that)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ou730Gx-ljc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "1f77881d-6b89-458f-9216-d6f390a3eefb"
      },
      "source": [
        "# check if code run on colab or local, if in Colab then True\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "# if run in Colab, then mount to run Google Drive file system\n",
        "if IN_COLAB:\n",
        "  # Mount google drive\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDeg8JQj5Ehf",
        "colab_type": "text"
      },
      "source": [
        "##  Constants declaration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQP0JUM5cNCv",
        "colab_type": "text"
      },
      "source": [
        "##### Constants that are expected to be directly changed (input parameters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt_lzmQQ5DDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# path to the directory with input\n",
        "PATH=\"/content/drive/My Drive/SKOLA/Bachelor_work/XR_HAND_roi_clahe/\"\n",
        "\n",
        "# constants declaration\n",
        "IMG_SIZE=(224,224)\n",
        "INPUT_SHAPE = (*IMG_SIZE, 3)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "NUMBER_CLASSES = 2\n",
        "NUMBER_EPOCHS = 50"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSD3vBDPbapr",
        "colab_type": "text"
      },
      "source": [
        "##### Deriving other constants from given values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQEZEgFIam0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def files_number(PATH):\n",
        "  \"\"\"find number of files(recursively) in given directory(path)\"\"\"\n",
        "  total = 0\n",
        "  for root, dirs, files in os.walk(PATH):\n",
        "      total += len(files)\n",
        "  return total\n",
        "\n",
        "# if run on local machine, change path to correspond my local system paths\n",
        "if not IN_COLAB:\n",
        "  PATH = \"G:\"+PATH[14:].replace('/', '\\\\\\\\')\n",
        "\n",
        "PATH_TRAIN = PATH + 'train'\n",
        "PATH_VALID = PATH + 'valid'\n",
        "# calculate number of steps per epoch and validation steps from input values\n",
        "# and constants\n",
        "train_img_num = files_number(PATH_TRAIN)\n",
        "valid_img_num = files_number(PATH_VALID)\n",
        "\n",
        "NUMBER_STEPS_PER_EPOCH = train_img_num // BATCH_SIZE\n",
        "NUMBER_VALIDATION_STEPS = valid_img_num // BATCH_SIZE\n",
        "\n",
        "print(\"Number of steps per epoch:\", NUMBER_STEPS_PER_EPOCH)\n",
        "print(\"Number of validation steps:\", NUMBER_VALIDATION_STEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyaNFRPd87u9",
        "colab_type": "text"
      },
      "source": [
        "## Data augmentation\n",
        "Currently image augmentation will be done by parameters of ImageDataGenerator.\n",
        "If in future this solution will be insufficient, I will change it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0SF2y318g9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ImageDataGenerator_def():\n",
        "  datagen = ImageDataGenerator(\n",
        "    # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    rotation_range=10,\n",
        "    # randomly shift images horizontally (fraction of total width)\n",
        "    width_shift_range=0.15,\n",
        "    # randomly shift images vertically` (fraction of total height)\n",
        "    height_shift_range=0.15,\n",
        "    # set range for random shear\n",
        "    shear_range=0.01,\n",
        "    # set range for random zoom\n",
        "    zoom_range=0.04,\n",
        "    # set mode for filling points outside the input boundaries\n",
        "    fill_mode='reflect',\n",
        "    # randomly flip images over horizontal axis\n",
        "    horizontal_flip=True, \n",
        "    # set rescaling factor (applied before any other transformation)\n",
        "    rescale=1. / 255,\n",
        "    # randomly change brightness of picture \n",
        "    brightness_range=[0.7,1.2],\n",
        "  )\n",
        "  return datagen\n",
        "\n",
        "def load_from_directory(dir_path, data_generator):\n",
        "  '''Load images from directory while transforming data (based on parameters),\n",
        "  contain other parameters for data augmentation'''\n",
        "  batches = data_generator.flow_from_directory(\n",
        "    # path to target directory from which data will be loaded\n",
        "    dir_path,\n",
        "    # resize all input images to IMG_SIZE\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle = True,\n",
        "  )\n",
        "  return batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-fmS0tr9WU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_generator = ImageDataGenerator_def()\n",
        "\n",
        "train_batches = load_from_directory(PATH_TRAIN, data_generator)\n",
        "valid_batches = load_from_directory(PATH_VALID, ImageDataGenerator(rescale=1. / 255))\n",
        "\n",
        "print(\"Found indices: \", end='')\n",
        "print(train_batches.class_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1v5wG3o8yNc",
        "colab_type": "text"
      },
      "source": [
        "## Auxiliary functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dBmWDHA8xOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_to_string(label):\n",
        "  '''Map label value to descriptive string'''\n",
        "  if(label == 0):\n",
        "    return \"Negative\"\n",
        "  else:\n",
        "    return \"Positive\"\n",
        "\n",
        "\n",
        "def show_sample_images(batches):\n",
        "  '''Show one batch of training images (max 25 images)'''\n",
        "  image_batch, label_batch = batches.next()\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for n in range(min(len(image_batch), 25)):\n",
        "    ax = plt.subplot(5,5,n+1)\n",
        "    plt.imshow(image_batch[n][:,:,0], cmap=cm.gray)\n",
        "    plt.title(label_to_string(label_batch[n]))\n",
        "    plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def load_keras_model(PATH_TO_MODEL):\n",
        "  '''Return loaded model saved model, based on value of PATH'''\n",
        "  return load_model(PATH_TO_MODEL)\n",
        "\n",
        "\n",
        "def plot_model_graph(model):\n",
        "  '''Print to output and save to file the graph of model layers\n",
        "  and its parameters, based on value of PATH'''\n",
        "  plot_model(model, to_file=PATH+\"model_arch.png\", show_shapes=True)\n",
        "\n",
        "\n",
        "def plot_training(history):\n",
        "  '''Plot diagnostic learning curves, print them to output and save them\n",
        "  to file'''\n",
        "  # plot loss\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.subplot(211)\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('Model accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Test'], loc='upper left')\n",
        "  plt.ylim(bottom=0.4, top=0.8)\n",
        "  plt.xlim(left=0, right = NUMBER_EPOCHS - 1)\n",
        "  \n",
        "  # plot accuracy\n",
        "  plt.subplot(212)\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('Model loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Test'], loc='upper left')\n",
        "  plt.ylim(bottom=0.5, top=1)\n",
        "  plt.xlim(left=0, right = NUMBER_EPOCHS - 1)\n",
        "  plt.tight_layout(pad=1.0)\n",
        "\n",
        "  # save plot to file\n",
        "  plt.savefig(PATH + 'acc_loss_plot_simple.png')\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "\n",
        "def cohen_kappa_metric(model_output, expected_output):\n",
        "  '''calculate cohen kappa metric between model's output and expected output \n",
        "  (golden standard defined in MURA dataset paper) \n",
        "  \n",
        "  Parameters\n",
        "  ----------\n",
        "  model_output : List\n",
        "    a list of zeroes and ones as predicted results from model (zero for negative)\n",
        "  expected_output : List\n",
        "    a list of zeroes and ones as reported results for testing data\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  Float\n",
        "    Cohen kappa metric score value\n",
        "  '''\n",
        "  from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "  if len(model_output) != len(expected_output):\n",
        "    print(\"Input strings for Kappa metrics don't have the same size.\\\n",
        "    Can't be compared\")\n",
        "    return 0.0\n",
        "  else:\n",
        "    return cohen_kappa_score(model_output, expected_output)\n",
        "\n",
        "\n",
        "def percentage(all_imgs, correct_imgs):\n",
        "  '''Calculate percentage of correct images'''\n",
        "  return 100 * float(correct_imgs)/float(all_imgs)\n",
        "\n",
        "\n",
        "def predict(model):\n",
        "  '''Use model to predict whether imgs are positive or negative\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : tensorflow.python.keras.engine.sequential.Sequential\n",
        "    model used for prediction\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  List\n",
        "    A list list of zeroes and ones as ground_truth values (one for positive and\n",
        "    zero for negative result)\n",
        "  List\n",
        "    A list list of zeroes and ones as prediction values (one for positive and\n",
        "    zero for negative result)\n",
        "  '''\n",
        "  ground_truth = []\n",
        "  predictions = []\n",
        "\n",
        "  test_batches = ImageDataGenerator(rescale=1. / 255).flow_from_directory(\n",
        "    # path to target directory from which data will be loaded\n",
        "    PATH_VALID,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=1,\n",
        "    class_mode='binary',\n",
        "    shuffle = False,\n",
        "  )\n",
        "\n",
        "  for i in range(len(test_batches.filenames)):\n",
        "    image, label = test_batches.next()\n",
        "\n",
        "    prediction = model.predict(image)\n",
        "    if prediction > 0.5:\n",
        "      predictions.append(1)\n",
        "    else:\n",
        "      predictions.append(0)\n",
        "\n",
        "    ground_truth.append(label.flat[0])\n",
        "  \n",
        "  return ground_truth, predictions\n",
        "\n",
        "\n",
        "def get_acc_kappa(PATH_TO_MODEL):\n",
        "  '''Call required functions to calculate kappa and accuracy\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  Float\n",
        "    accuracy value\n",
        "  Float\n",
        "    kappa value\n",
        "  '''\n",
        "  model = load_keras_model(PATH_TO_MODEL)\n",
        "  ground_truth, predictions = predict(model)\n",
        "\n",
        "  new_gt = []\n",
        "  for i in ground_truth:\n",
        "    new_gt.append(int(i))\n",
        "\n",
        "  correct_cnt = 0\n",
        "  for i in range(len(new_gt)):\n",
        "    if predictions[i] == new_gt[i]:\n",
        "      correct_cnt += 1\n",
        "\n",
        "  kappa = cohen_kappa_metric(new_gt, predictions)\n",
        "  accuracy = percentage(len(new_gt), correct_cnt)\n",
        "\n",
        "  print(\"Test images:\", len(new_gt))\n",
        "  print(\"Correctly predicted:\", correct_cnt)\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  print(\"Kappa   :\", kappa)\n",
        "\n",
        "  return accuracy, kappa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7QB-EFKyiD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display batch if training examples and validation examples\n",
        "show_sample_images(train_batches)\n",
        "show_sample_images(valid_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WznMKC7APFCX",
        "colab_type": "text"
      },
      "source": [
        "## Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYmbTrOnq3iL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Activation function is method that define the output of neuron, different\n",
        "functions use distinctive methods of how to figure out output.\n",
        "I am using ReLU - Rectified linear unit. It is simple but effective function,\n",
        "x = max(0,x)'''\n",
        "ACTIVATION_FUNCTION='relu'\n",
        "\n",
        "'''Kernel initializer define method used in setting the initial random weights\n",
        "in layers. \n",
        "Currently using he_uniform, draws samples from a uniform distribution within\n",
        "[-limit, limit] where limit is sqrt(6 / fan_in) where fan_in\n",
        "is the number of input units in the weight ten'''\n",
        "KERNER_INITIALIZER=he_uniform(0)\n",
        "\n",
        "'''\n",
        "Padding is a method to extend input image, so filter kernel can work as intended\n",
        "even around borders.\n",
        "Same - is method that guarantee output have SAME spatial dimensions as input'''\n",
        "PADDING='same'\n",
        "\n",
        "'''Optimizer is algorithm that change the attributes of neural network\n",
        " (weights and learning rate) in order to reduce loss value\n",
        " Stochastic gradient descent, which is improved by momentum method,\n",
        " lr is learning rate - it determines how big changes can be made in each step\n",
        " during training model, bigger lr means faster learning, but step too big can\n",
        " miss the best solution, thats why i can't be way to big'''\n",
        "OPTIMIZER=SGD(lr=0.01, momentum=0.9, decay=0.01/NUMBER_EPOCHS)\n",
        "\n",
        "'''Loss function evaluate loss/cost of specific event, in this case \n",
        "loss function describe how well does model perform by comparing ground truth(\n",
        "label of what class is the training input image) with output from model'''\n",
        "LOSS_FUNCTION='binary_crossentropy'\n",
        "\n",
        "def three_block_VGG():\n",
        "  \"\"\"Three Block VGG Model\"\"\"\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(32, (3, 3), activation=ACTIVATION_FUNCTION, kernel_initializer=KERNER_INITIALIZER, padding=PADDING, input_shape=INPUT_SHAPE))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), activation=ACTIVATION_FUNCTION, kernel_initializer=KERNER_INITIALIZER, padding=PADDING))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), activation=ACTIVATION_FUNCTION, kernel_initializer=KERNER_INITIALIZER, padding=PADDING))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.1))\n",
        "\n",
        "  model.add(Conv2D(256, (3, 3), activation=ACTIVATION_FUNCTION, kernel_initializer=KERNER_INITIALIZER, padding=PADDING))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  \n",
        "  model.add(Dense(256, activation=ACTIVATION_FUNCTION, kernel_initializer=KERNER_INITIALIZER))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  # compile model\n",
        "  model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNCTION, metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slo1wjopo2cE",
        "colab_type": "text"
      },
      "source": [
        "## Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlF3BkGpcA8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize model\n",
        "model = three_block_VGG()\n",
        "\n",
        "# print summary info about model and its layers\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLu4W0VHdw8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saves the best model\n",
        "model_checkpoint = ModelCheckpoint(filepath=PATH+\"best_model_simple.h5\", monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
        "\n",
        "# training model\n",
        "history = model.fit(train_batches,\n",
        "                    steps_per_epoch= NUMBER_STEPS_PER_EPOCH,\n",
        "                    validation_data = valid_batches,\n",
        "                    validation_steps = NUMBER_VALIDATION_STEPS,\n",
        "                    epochs = NUMBER_EPOCHS,\n",
        "                    callbacks=[model_checkpoint]\n",
        "                    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hc8gkuG4IYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show plot of accuracy and loss (both training and validation) during training\n",
        "plot_training(history) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W34f1Iv-FLyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate and display kappa and accuracy of the model\n",
        "get_acc_kappa(PATH+\"best_model_simple.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}